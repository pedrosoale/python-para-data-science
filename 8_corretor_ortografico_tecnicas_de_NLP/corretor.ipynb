{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# baixa o arquivo e apresenta os 500 primeiros caracteres\n",
    "with open(\"artigos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artigos) # mostra a quantidade de caracteres do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = \"Olá Alexandre, tudo bem?\"\n",
    "tokens = texto_exemplo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', 'Alexandre,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização de um texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alexandre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando NLTK\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', 'Alexandre', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'palavra'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'Alexandre', 'tudo', 'bem']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimina pontuação e símbolos\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403106\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f\"O número de palavras é {len(lista_palavras)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo e testando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = \"lgica\"\n",
    "(lista[:1], lista[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'lgica'), ('l', 'gica'), ('lg', 'ica'), ('lgi', 'ca'), ('lgic', 'a'), ('lgica', '')]\n",
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lgica\"\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    print(fatias)\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023815075935361914"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / total_palavras\n",
    "\n",
    "probabilidade(\"lógica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'lgica'), ('l', 'gica'), ('lg', 'ica'), ('lgi', 'ca'), ('lgic', 'a'), ('lgica', '')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando o Corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding=\"utf-8\")\n",
    "    for linha in f: \n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "lista_teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'pyodemos'), ('p', 'yodemos'), ('py', 'odemos'), ('pyo', 'demos'), ('pyod', 'emos'), ('pyode', 'mos'), ('pyodem', 'os'), ('pyodemo', 's'), ('pyodemos', '')]\n",
      "[('', 'esje'), ('e', 'sje'), ('es', 'je'), ('esj', 'e'), ('esje', '')]\n",
      "[('', 'jrá'), ('j', 'rá'), ('jr', 'á'), ('jrá', '')]\n",
      "[('', 'nossov'), ('n', 'ossov'), ('no', 'ssov'), ('nos', 'sov'), ('noss', 'ov'), ('nosso', 'v'), ('nossov', '')]\n",
      "[('', 'sãêo'), ('s', 'ãêo'), ('sã', 'êo'), ('sãê', 'o'), ('sãêo', '')]\n",
      "[('', 'dosa'), ('d', 'osa'), ('do', 'sa'), ('dos', 'a'), ('dosa', '')]\n",
      "[('', 'muifo'), ('m', 'uifo'), ('mu', 'ifo'), ('mui', 'fo'), ('muif', 'o'), ('muifo', '')]\n",
      "[('', 'iômagem'), ('i', 'ômagem'), ('iô', 'magem'), ('iôm', 'agem'), ('iôma', 'gem'), ('iômag', 'em'), ('iômage', 'm'), ('iômagem', '')]\n",
      "[('', 'ósua'), ('ó', 'sua'), ('ós', 'ua'), ('ósu', 'a'), ('ósua', '')]\n",
      "[('', 'tambéùm'), ('t', 'ambéùm'), ('ta', 'mbéùm'), ('tam', 'béùm'), ('tamb', 'éùm'), ('també', 'ùm'), ('tambéù', 'm'), ('tambéùm', '')]\n",
      "[('', 'eme'), ('e', 'me'), ('em', 'e'), ('eme', '')]\n",
      "[('', 'èazer'), ('è', 'azer'), ('èa', 'zer'), ('èaz', 'er'), ('èaze', 'r'), ('èazer', '')]\n",
      "[('', 'temfs'), ('t', 'emfs'), ('te', 'mfs'), ('tem', 'fs'), ('temf', 's'), ('temfs', '')]\n",
      "[('', 'eàssa'), ('e', 'àssa'), ('eà', 'ssa'), ('eàs', 'sa'), ('eàss', 'a'), ('eàssa', '')]\n",
      "[('', 'quaôdo'), ('q', 'uaôdo'), ('qu', 'aôdo'), ('qua', 'ôdo'), ('quaô', 'do'), ('quaôd', 'o'), ('quaôdo', '')]\n",
      "[('', 'vamvos'), ('v', 'amvos'), ('va', 'mvos'), ('vam', 'vos'), ('vamv', 'os'), ('vamvo', 's'), ('vamvos', '')]\n",
      "[('', 'hsobre'), ('h', 'sobre'), ('hs', 'obre'), ('hso', 'bre'), ('hsob', 're'), ('hsobr', 'e'), ('hsobre', '')]\n",
      "[('', 'sjava'), ('s', 'java'), ('sj', 'ava'), ('sja', 'va'), ('sjav', 'a'), ('sjava', '')]\n",
      "[('', 'daõs'), ('d', 'aõs'), ('da', 'õs'), ('daõ', 's'), ('daõs', '')]\n",
      "[('', 'agorah'), ('a', 'gorah'), ('ag', 'orah'), ('ago', 'rah'), ('agor', 'ah'), ('agora', 'h'), ('agorah', '')]\n",
      "[('', 'eòtá'), ('e', 'òtá'), ('eò', 'tá'), ('eòt', 'á'), ('eòtá', '')]\n",
      "[('', 'céda'), ('c', 'éda'), ('cé', 'da'), ('céd', 'a'), ('céda', '')]\n",
      "[('', 'zmesmo'), ('z', 'mesmo'), ('zm', 'esmo'), ('zme', 'smo'), ('zmes', 'mo'), ('zmesm', 'o'), ('zmesmo', '')]\n",
      "[('', 'noâ'), ('n', 'oâ'), ('no', 'â'), ('noâ', '')]\n",
      "[('', 'fobma'), ('f', 'obma'), ('fo', 'bma'), ('fob', 'ma'), ('fobm', 'a'), ('fobma', '')]\n",
      "[('', 'sejéa'), ('s', 'ejéa'), ('se', 'jéa'), ('sej', 'éa'), ('sejé', 'a'), ('sejéa', '')]\n",
      "[('', 'enêão'), ('e', 'nêão'), ('en', 'êão'), ('enê', 'ão'), ('enêã', 'o'), ('enêão', '')]\n",
      "[('', 'èriar'), ('è', 'riar'), ('èr', 'iar'), ('èri', 'ar'), ('èria', 'r'), ('èriar', '')]\n",
      "[('', 'cóeigo'), ('c', 'óeigo'), ('có', 'eigo'), ('cóe', 'igo'), ('cóei', 'go'), ('cóeig', 'o'), ('cóeigo', '')]\n",
      "[('', 'casío'), ('c', 'asío'), ('ca', 'sío'), ('cas', 'ío'), ('casí', 'o'), ('casío', '')]\n",
      "[('', 'áexemplo'), ('á', 'exemplo'), ('áe', 'xemplo'), ('áex', 'emplo'), ('áexe', 'mplo'), ('áexem', 'plo'), ('áexemp', 'lo'), ('áexempl', 'o'), ('áexemplo', '')]\n",
      "[('', 'tĩem'), ('t', 'ĩem'), ('tĩ', 'em'), ('tĩe', 'm'), ('tĩem', '')]\n",
      "[('', 'usuárôio'), ('u', 'suárôio'), ('us', 'uárôio'), ('usu', 'árôio'), ('usuá', 'rôio'), ('usuár', 'ôio'), ('usuárô', 'io'), ('usuárôi', 'o'), ('usuárôio', '')]\n",
      "[('', 'dfados'), ('d', 'fados'), ('df', 'ados'), ('dfa', 'dos'), ('dfad', 'os'), ('dfado', 's'), ('dfados', '')]\n",
      "[('', 'pgthon'), ('p', 'gthon'), ('pg', 'thon'), ('pgt', 'hon'), ('pgth', 'on'), ('pgtho', 'n'), ('pgthon', '')]\n",
      "[('', 'nossah'), ('n', 'ossah'), ('no', 'ssah'), ('nos', 'sah'), ('noss', 'ah'), ('nossa', 'h'), ('nossah', '')]\n",
      "[('', 'alémè'), ('a', 'lémè'), ('al', 'émè'), ('alé', 'mè'), ('além', 'è'), ('alémè', '')]\n",
      "[('', 'asõim'), ('a', 'sõim'), ('as', 'õim'), ('asõ', 'im'), ('asõi', 'm'), ('asõim', '')]\n",
      "[('', 'teb'), ('t', 'eb'), ('te', 'b'), ('teb', '')]\n",
      "[('', 'atĩ'), ('a', 'tĩ'), ('at', 'ĩ'), ('atĩ', '')]\n",
      "[('', 'âem'), ('â', 'em'), ('âe', 'm'), ('âem', '')]\n",
      "[('', 'desigen'), ('d', 'esigen'), ('de', 'sigen'), ('des', 'igen'), ('desi', 'gen'), ('desig', 'en'), ('desige', 'n'), ('desigen', '')]\n",
      "[('', 'trabalàho'), ('t', 'rabalàho'), ('tr', 'abalàho'), ('tra', 'balàho'), ('trab', 'alàho'), ('traba', 'làho'), ('trabal', 'àho'), ('trabalà', 'ho'), ('trabalàh', 'o'), ('trabalàho', '')]\n",
      "[('', 'foo'), ('f', 'oo'), ('fo', 'o'), ('foo', '')]\n",
      "[('', 'apenaũ'), ('a', 'penaũ'), ('ap', 'enaũ'), ('ape', 'naũ'), ('apen', 'aũ'), ('apena', 'ũ'), ('apenaũ', '')]\n",
      "[('', 'empresà'), ('e', 'mpresà'), ('em', 'presà'), ('emp', 'resà'), ('empr', 'esà'), ('empre', 'sà'), ('empres', 'à'), ('empresà', '')]\n",
      "[('', 'valíor'), ('v', 'alíor'), ('va', 'líor'), ('val', 'íor'), ('valí', 'or'), ('valío', 'r'), ('valíor', '')]\n",
      "[('', 'serr'), ('s', 'err'), ('se', 'rr'), ('ser', 'r'), ('serr', '')]\n",
      "[('', 'entke'), ('e', 'ntke'), ('en', 'tke'), ('ent', 'ke'), ('entk', 'e'), ('entke', '')]\n",
      "[('', 'méqodo'), ('m', 'éqodo'), ('mé', 'qodo'), ('méq', 'odo'), ('méqo', 'do'), ('méqod', 'o'), ('méqodo', '')]\n",
      "[('', 'precisamops'), ('p', 'recisamops'), ('pr', 'ecisamops'), ('pre', 'cisamops'), ('prec', 'isamops'), ('preci', 'samops'), ('precis', 'amops'), ('precisa', 'mops'), ('precisam', 'ops'), ('precisamo', 'ps'), ('precisamop', 's'), ('precisamops', '')]\n",
      "[('', 'ainàa'), ('a', 'inàa'), ('ai', 'nàa'), ('ain', 'àa'), ('ainà', 'a'), ('ainàa', '')]\n",
      "[('', 'van'), ('v', 'an'), ('va', 'n'), ('van', '')]\n",
      "[('', 'ûconteúdo'), ('û', 'conteúdo'), ('ûc', 'onteúdo'), ('ûco', 'nteúdo'), ('ûcon', 'teúdo'), ('ûcont', 'eúdo'), ('ûconte', 'údo'), ('ûconteú', 'do'), ('ûconteúd', 'o'), ('ûconteúdo', '')]\n",
      "[('', 'çeus'), ('ç', 'eus'), ('çe', 'us'), ('çeu', 's'), ('çeus', '')]\n",
      "[('', 'eû'), ('e', 'û'), ('eû', '')]\n",
      "[('', 'todtos'), ('t', 'odtos'), ('to', 'dtos'), ('tod', 'tos'), ('todt', 'os'), ('todto', 's'), ('todtos', '')]\n",
      "[('', 'temeo'), ('t', 'emeo'), ('te', 'meo'), ('tem', 'eo'), ('teme', 'o'), ('temeo', '')]\n",
      "[('', 'semre'), ('s', 'emre'), ('se', 'mre'), ('sem', 're'), ('semr', 'e'), ('semre', '')]\n",
      "[('', 'quakl'), ('q', 'uakl'), ('qu', 'akl'), ('qua', 'kl'), ('quak', 'l'), ('quakl', '')]\n",
      "[('', 'elaá'), ('e', 'laá'), ('el', 'aá'), ('ela', 'á'), ('elaá', '')]\n",
      "[('', 'síó'), ('s', 'íó'), ('sí', 'ó'), ('síó', '')]\n",
      "[('', 'utiqizar'), ('u', 'tiqizar'), ('ut', 'iqizar'), ('uti', 'qizar'), ('utiq', 'izar'), ('utiqi', 'zar'), ('utiqiz', 'ar'), ('utiqiza', 'r'), ('utiqizar', '')]\n",
      "[('', 'prhojeto'), ('p', 'rhojeto'), ('pr', 'hojeto'), ('prh', 'ojeto'), ('prho', 'jeto'), ('prhoj', 'eto'), ('prhoje', 'to'), ('prhojet', 'o'), ('prhojeto', '')]\n",
      "[('', 'siàe'), ('s', 'iàe'), ('si', 'àe'), ('sià', 'e'), ('siàe', '')]\n",
      "[('', 'seém'), ('s', 'eém'), ('se', 'ém'), ('seé', 'm'), ('seém', '')]\n",
      "[('', 'peln'), ('p', 'eln'), ('pe', 'ln'), ('pel', 'n'), ('peln', '')]\n",
      "[('', 'aléra'), ('a', 'léra'), ('al', 'éra'), ('alé', 'ra'), ('alér', 'a'), ('aléra', '')]\n",
      "[('', 'tdia'), ('t', 'dia'), ('td', 'ia'), ('tdi', 'a'), ('tdia', '')]\n",
      "[('', 'tuúo'), ('t', 'uúo'), ('tu', 'úo'), ('tuú', 'o'), ('tuúo', '')]\n",
      "[('', 'kpodemos'), ('k', 'podemos'), ('kp', 'odemos'), ('kpo', 'demos'), ('kpod', 'emos'), ('kpode', 'mos'), ('kpodem', 'os'), ('kpodemo', 's'), ('kpodemos', '')]\n",
      "[('', 'eẽsse'), ('e', 'ẽsse'), ('eẽ', 'sse'), ('eẽs', 'se'), ('eẽss', 'e'), ('eẽsse', '')]\n",
      "[('', 'jé'), ('j', 'é'), ('jé', '')]\n",
      "[('', 'nçosso'), ('n', 'çosso'), ('nç', 'osso'), ('nço', 'sso'), ('nços', 'so'), ('nçoss', 'o'), ('nçosso', '')]\n",
      "[('', 'sãô'), ('s', 'ãô'), ('sã', 'ô'), ('sãô', '')]\n",
      "[('', 'odos'), ('o', 'dos'), ('od', 'os'), ('odo', 's'), ('odos', '')]\n",
      "[('', 'tuito'), ('t', 'uito'), ('tu', 'ito'), ('tui', 'to'), ('tuit', 'o'), ('tuito', '')]\n",
      "[('', 'imõgem'), ('i', 'mõgem'), ('im', 'õgem'), ('imõ', 'gem'), ('imõg', 'em'), ('imõge', 'm'), ('imõgem', '')]\n",
      "[('', 'siua'), ('s', 'iua'), ('si', 'ua'), ('siu', 'a'), ('siua', '')]\n",
      "[('', 'tamvbém'), ('t', 'amvbém'), ('ta', 'mvbém'), ('tam', 'vbém'), ('tamv', 'bém'), ('tamvb', 'ém'), ('tamvbé', 'm'), ('tamvbém', '')]\n",
      "[('', 'elpe'), ('e', 'lpe'), ('el', 'pe'), ('elp', 'e'), ('elpe', '')]\n",
      "[('', 'façzer'), ('f', 'açzer'), ('fa', 'çzer'), ('faç', 'zer'), ('façz', 'er'), ('façze', 'r'), ('façzer', '')]\n",
      "[('', 'teos'), ('t', 'eos'), ('te', 'os'), ('teo', 's'), ('teos', '')]\n",
      "[('', 'eũsa'), ('e', 'ũsa'), ('eũ', 'sa'), ('eũs', 'a'), ('eũsa', '')]\n",
      "[('', 'quaìdo'), ('q', 'uaìdo'), ('qu', 'aìdo'), ('qua', 'ìdo'), ('quaì', 'do'), ('quaìd', 'o'), ('quaìdo', '')]\n",
      "[('', 'vjmos'), ('v', 'jmos'), ('vj', 'mos'), ('vjm', 'os'), ('vjmo', 's'), ('vjmos', '')]\n",
      "[('', 'sxobre'), ('s', 'xobre'), ('sx', 'obre'), ('sxo', 'bre'), ('sxob', 're'), ('sxobr', 'e'), ('sxobre', '')]\n",
      "[('', 'jkva'), ('j', 'kva'), ('jk', 'va'), ('jkv', 'a'), ('jkva', '')]\n",
      "[('', 'dms'), ('d', 'ms'), ('dm', 's'), ('dms', '')]\n",
      "[('', 'agtora'), ('a', 'gtora'), ('ag', 'tora'), ('agt', 'ora'), ('agto', 'ra'), ('agtor', 'a'), ('agtora', '')]\n",
      "[('', 'esútá'), ('e', 'sútá'), ('es', 'útá'), ('esú', 'tá'), ('esút', 'á'), ('esútá', '')]\n",
      "[('', 'cava'), ('c', 'ava'), ('ca', 'va'), ('cav', 'a'), ('cava', '')]\n",
      "[('', 'medmo'), ('m', 'edmo'), ('me', 'dmo'), ('med', 'mo'), ('medm', 'o'), ('medmo', '')]\n",
      "[('', 'ános'), ('á', 'nos'), ('án', 'os'), ('áno', 's'), ('ános', '')]\n",
      "[('', 'forûa'), ('f', 'orûa'), ('fo', 'rûa'), ('for', 'ûa'), ('forû', 'a'), ('forûa', '')]\n",
      "[('', 'smeja'), ('s', 'meja'), ('sm', 'eja'), ('sme', 'ja'), ('smej', 'a'), ('smeja', '')]\n",
      "[('', 'enjtão'), ('e', 'njtão'), ('en', 'jtão'), ('enj', 'tão'), ('enjt', 'ão'), ('enjtã', 'o'), ('enjtão', '')]\n",
      "[('', 'criôar'), ('c', 'riôar'), ('cr', 'iôar'), ('cri', 'ôar'), ('criô', 'ar'), ('criôa', 'r'), ('criôar', '')]\n",
      "[('', 'cóàigo'), ('c', 'óàigo'), ('có', 'àigo'), ('cóà', 'igo'), ('cóài', 'go'), ('cóàig', 'o'), ('cóàigo', '')]\n",
      "[('', 'èaso'), ('è', 'aso'), ('èa', 'so'), ('èas', 'o'), ('èaso', '')]\n",
      "[('', 'exbemplo'), ('e', 'xbemplo'), ('ex', 'bemplo'), ('exb', 'emplo'), ('exbe', 'mplo'), ('exbem', 'plo'), ('exbemp', 'lo'), ('exbempl', 'o'), ('exbemplo', '')]\n",
      "[('', 'túem'), ('t', 'úem'), ('tú', 'em'), ('túe', 'm'), ('túem', '')]\n",
      "[('', 'usuárin'), ('u', 'suárin'), ('us', 'uárin'), ('usu', 'árin'), ('usuá', 'rin'), ('usuár', 'in'), ('usuári', 'n'), ('usuárin', '')]\n",
      "[('', 'daáos'), ('d', 'aáos'), ('da', 'áos'), ('daá', 'os'), ('daáo', 's'), ('daáos', '')]\n",
      "[('', 'pythoçn'), ('p', 'ythoçn'), ('py', 'thoçn'), ('pyt', 'hoçn'), ('pyth', 'oçn'), ('pytho', 'çn'), ('pythoç', 'n'), ('pythoçn', '')]\n",
      "[('', 'nossk'), ('n', 'ossk'), ('no', 'ssk'), ('nos', 'sk'), ('noss', 'k'), ('nossk', '')]\n",
      "[('', 'âlém'), ('â', 'lém'), ('âl', 'ém'), ('âlé', 'm'), ('âlém', '')]\n",
      "[('', 'aóssim'), ('a', 'óssim'), ('aó', 'ssim'), ('aós', 'sim'), ('aóss', 'im'), ('aóssi', 'm'), ('aóssim', '')]\n",
      "[('', 'tãer'), ('t', 'ãer'), ('tã', 'er'), ('tãe', 'r'), ('tãer', '')]\n",
      "[('', 'vté'), ('v', 'té'), ('vt', 'é'), ('vté', '')]\n",
      "[('', 'búm'), ('b', 'úm'), ('bú', 'm'), ('búm', '')]\n",
      "[('', 'íesign'), ('í', 'esign'), ('íe', 'sign'), ('íes', 'ign'), ('íesi', 'gn'), ('íesig', 'n'), ('íesign', '')]\n",
      "[('', 'trabèalho'), ('t', 'rabèalho'), ('tr', 'abèalho'), ('tra', 'bèalho'), ('trab', 'èalho'), ('trabè', 'alho'), ('trabèa', 'lho'), ('trabèal', 'ho'), ('trabèalh', 'o'), ('trabèalho', '')]\n",
      "[('', 'kfoi'), ('k', 'foi'), ('kf', 'oi'), ('kfo', 'i'), ('kfoi', '')]\n",
      "[('', 'aapenas'), ('a', 'apenas'), ('aa', 'penas'), ('aap', 'enas'), ('aape', 'nas'), ('aapen', 'as'), ('aapena', 's'), ('aapenas', '')]\n",
      "[('', 'pmpresa'), ('p', 'mpresa'), ('pm', 'presa'), ('pmp', 'resa'), ('pmpr', 'esa'), ('pmpre', 'sa'), ('pmpres', 'a'), ('pmpresa', '')]\n",
      "[('', 'valoqr'), ('v', 'aloqr'), ('va', 'loqr'), ('val', 'oqr'), ('valo', 'qr'), ('valoq', 'r'), ('valoqr', '')]\n",
      "[('', 'sçerá'), ('s', 'çerá'), ('sç', 'erá'), ('sçe', 'rá'), ('sçer', 'á'), ('sçerá', '')]\n",
      "[('', 'entró'), ('e', 'ntró'), ('en', 'tró'), ('ent', 'ró'), ('entr', 'ó'), ('entró', '')]\n",
      "[('', 'nétodo'), ('n', 'étodo'), ('né', 'todo'), ('nét', 'odo'), ('néto', 'do'), ('nétod', 'o'), ('nétodo', '')]\n",
      "[('', 'prefcisamos'), ('p', 'refcisamos'), ('pr', 'efcisamos'), ('pre', 'fcisamos'), ('pref', 'cisamos'), ('prefc', 'isamos'), ('prefci', 'samos'), ('prefcis', 'amos'), ('prefcisa', 'mos'), ('prefcisam', 'os'), ('prefcisamo', 's'), ('prefcisamos', '')]\n",
      "[('', 'sainda'), ('s', 'ainda'), ('sa', 'inda'), ('sai', 'nda'), ('sain', 'da'), ('saind', 'a'), ('sainda', '')]\n",
      "[('', 'uai'), ('u', 'ai'), ('ua', 'i'), ('uai', '')]\n",
      "[('', 'cĩonteúdo'), ('c', 'ĩonteúdo'), ('cĩ', 'onteúdo'), ('cĩo', 'nteúdo'), ('cĩon', 'teúdo'), ('cĩont', 'eúdo'), ('cĩonte', 'údo'), ('cĩonteú', 'do'), ('cĩonteúd', 'o'), ('cĩonteúdo', '')]\n",
      "[('', 'sâus'), ('s', 'âus'), ('sâ', 'us'), ('sâu', 's'), ('sâus', '')]\n",
      "[('', 'ìeu'), ('ì', 'eu'), ('ìe', 'u'), ('ìeu', '')]\n",
      "[('', 'todás'), ('t', 'odás'), ('to', 'dás'), ('tod', 'ás'), ('todá', 's'), ('todás', '')]\n",
      "[('', 'utempo'), ('u', 'tempo'), ('ut', 'empo'), ('ute', 'mpo'), ('utem', 'po'), ('utemp', 'o'), ('utempo', '')]\n",
      "[('', 'sempce'), ('s', 'empce'), ('se', 'mpce'), ('sem', 'pce'), ('semp', 'ce'), ('sempc', 'e'), ('sempce', '')]\n",
      "[('', 'fual'), ('f', 'ual'), ('fu', 'al'), ('fua', 'l'), ('fual', '')]\n",
      "[('', 'elal'), ('e', 'lal'), ('el', 'al'), ('ela', 'l'), ('elal', '')]\n",
      "[('', 'skó'), ('s', 'kó'), ('sk', 'ó'), ('skó', '')]\n",
      "[('', 'utilĩzar'), ('u', 'tilĩzar'), ('ut', 'ilĩzar'), ('uti', 'lĩzar'), ('util', 'ĩzar'), ('utilĩ', 'zar'), ('utilĩz', 'ar'), ('utilĩza', 'r'), ('utilĩzar', '')]\n",
      "[('', 'proójeto'), ('p', 'roójeto'), ('pr', 'oójeto'), ('pro', 'ójeto'), ('proó', 'jeto'), ('proój', 'eto'), ('proóje', 'to'), ('proójet', 'o'), ('proójeto', '')]\n",
      "[('', 'isite'), ('i', 'site'), ('is', 'ite'), ('isi', 'te'), ('isit', 'e'), ('isite', '')]\n",
      "[('', 'secm'), ('s', 'ecm'), ('se', 'cm'), ('sec', 'm'), ('secm', '')]\n",
      "[('', 'pẽlo'), ('p', 'ẽlo'), ('pẽ', 'lo'), ('pẽl', 'o'), ('pẽlo', '')]\n",
      "[('', 'aluéa'), ('a', 'luéa'), ('al', 'uéa'), ('alu', 'éa'), ('alué', 'a'), ('aluéa', '')]\n",
      "[('', 'dil'), ('d', 'il'), ('di', 'l'), ('dil', '')]\n",
      "[('', 'tudy'), ('t', 'udy'), ('tu', 'dy'), ('tud', 'y'), ('tudy', '')]\n",
      "[('', 'qelay'), ('q', 'elay'), ('qe', 'lay'), ('qel', 'ay'), ('qela', 'y'), ('qelay', '')]\n",
      "[('', 'sód'), ('s', 'ód'), ('só', 'd'), ('sód', '')]\n",
      "[('', 'dtilizacr'), ('d', 'tilizacr'), ('dt', 'ilizacr'), ('dti', 'lizacr'), ('dtil', 'izacr'), ('dtili', 'zacr'), ('dtiliz', 'acr'), ('dtiliza', 'cr'), ('dtilizac', 'r'), ('dtilizacr', '')]\n",
      "[('', 'bprojõto'), ('b', 'projõto'), ('bp', 'rojõto'), ('bpr', 'ojõto'), ('bpro', 'jõto'), ('bproj', 'õto'), ('bprojõ', 'to'), ('bprojõt', 'o'), ('bprojõto', '')]\n",
      "[('', 'ysiteo'), ('y', 'siteo'), ('ys', 'iteo'), ('ysi', 'teo'), ('ysit', 'eo'), ('ysite', 'o'), ('ysiteo', '')]\n",
      "[('', 'sõêm'), ('s', 'õêm'), ('sõ', 'êm'), ('sõê', 'm'), ('sõêm', '')]\n",
      "[('', 'peàli'), ('p', 'eàli'), ('pe', 'àli'), ('peà', 'li'), ('peàl', 'i'), ('peàli', '')]\n",
      "[('', 'asuraó'), ('a', 'suraó'), ('as', 'uraó'), ('asu', 'raó'), ('asur', 'aó'), ('asura', 'ó'), ('asuraó', '')]\n",
      "[('', 'deiìa'), ('d', 'eiìa'), ('de', 'iìa'), ('dei', 'ìa'), ('deiì', 'a'), ('deiìa', '')]\n",
      "[('', 'tuĩdoì'), ('t', 'uĩdoì'), ('tu', 'ĩdoì'), ('tuĩ', 'doì'), ('tuĩd', 'oì'), ('tuĩdo', 'ì'), ('tuĩdoì', '')]\n",
      "[('', 'eúaa'), ('e', 'úaa'), ('eú', 'aa'), ('eúa', 'a'), ('eúaa', '')]\n",
      "[('', 'ró'), ('r', 'ó'), ('ró', '')]\n",
      "[('', 'utilizẽaçr'), ('u', 'tilizẽaçr'), ('ut', 'ilizẽaçr'), ('uti', 'lizẽaçr'), ('util', 'izẽaçr'), ('utili', 'zẽaçr'), ('utiliz', 'ẽaçr'), ('utilizẽ', 'açr'), ('utilizẽa', 'çr'), ('utilizẽaç', 'r'), ('utilizẽaçr', '')]\n",
      "[('', 'prêjetó'), ('p', 'rêjetó'), ('pr', 'êjetó'), ('prê', 'jetó'), ('prêj', 'etó'), ('prêje', 'tó'), ('prêjet', 'ó'), ('prêjetó', '')]\n",
      "[('', 'sqiqte'), ('s', 'qiqte'), ('sq', 'iqte'), ('sqi', 'qte'), ('sqiq', 'te'), ('sqiqt', 'e'), ('sqiqte', '')]\n",
      "[('', 'sũexm'), ('s', 'ũexm'), ('sũ', 'exm'), ('sũe', 'xm'), ('sũex', 'm'), ('sũexm', '')]\n",
      "[('', 'pçlxo'), ('p', 'çlxo'), ('pç', 'lxo'), ('pçl', 'xo'), ('pçlx', 'o'), ('pçlxo', '')]\n",
      "[('', 'uluraa'), ('u', 'luraa'), ('ul', 'uraa'), ('ulu', 'raa'), ('ulur', 'aa'), ('ulura', 'a'), ('uluraa', '')]\n",
      "[('', 'dĩaz'), ('d', 'ĩaz'), ('dĩ', 'az'), ('dĩa', 'z'), ('dĩaz', '')]\n",
      "[('', 'kzudo'), ('k', 'zudo'), ('kz', 'udo'), ('kzu', 'do'), ('kzud', 'o'), ('kzudo', '')]\n",
      "[('', 'correptor'), ('c', 'orreptor'), ('co', 'rreptor'), ('cor', 'reptor'), ('corr', 'eptor'), ('corre', 'ptor'), ('correp', 'tor'), ('corrept', 'or'), ('correpto', 'r'), ('correptor', '')]\n",
      "[('', 'trtica'), ('t', 'rtica'), ('tr', 'tica'), ('trt', 'ica'), ('trti', 'ca'), ('trtic', 'a'), ('trtica', '')]\n",
      "[('', 'ewpoderamento'), ('e', 'wpoderamento'), ('ew', 'poderamento'), ('ewp', 'oderamento'), ('ewpo', 'deramento'), ('ewpod', 'eramento'), ('ewpode', 'ramento'), ('ewpoder', 'amento'), ('ewpodera', 'mento'), ('ewpoderam', 'ento'), ('ewpoderame', 'nto'), ('ewpoderamen', 'to'), ('ewpoderament', 'o'), ('ewpoderamento', '')]\n",
      "[('', 'lifux'), ('l', 'ifux'), ('li', 'fux'), ('lif', 'ux'), ('lifu', 'x'), ('lifux', '')]\n",
      "[('', 'cachoçro'), ('c', 'achoçro'), ('ca', 'choçro'), ('cac', 'hoçro'), ('cach', 'oçro'), ('cacho', 'çro'), ('cachoç', 'ro'), ('cachoçr', 'o'), ('cachoçro', '')]\n",
      "[('', 'îgato'), ('î', 'gato'), ('îg', 'ato'), ('îga', 'to'), ('îgat', 'o'), ('îgato', '')]\n",
      "[('', 'cakvalo'), ('c', 'akvalo'), ('ca', 'kvalo'), ('cak', 'valo'), ('cakv', 'alo'), ('cakva', 'lo'), ('cakval', 'o'), ('cakvalo', '')]\n",
      "[('', 'relógiuo'), ('r', 'elógiuo'), ('re', 'lógiuo'), ('rel', 'ógiuo'), ('reló', 'giuo'), ('relóg', 'iuo'), ('relógi', 'uo'), ('relógiu', 'o'), ('relógiuo', '')]\n",
      "[('', 'canelac'), ('c', 'anelac'), ('ca', 'nelac'), ('can', 'elac'), ('cane', 'lac'), ('canel', 'ac'), ('canela', 'c'), ('canelac', '')]\n",
      "[('', 'tênisy'), ('t', 'ênisy'), ('tê', 'nisy'), ('tên', 'isy'), ('têni', 'sy'), ('tênis', 'y'), ('tênisy', '')]\n",
      "[('', 'anciosa'), ('a', 'nciosa'), ('an', 'ciosa'), ('anc', 'iosa'), ('anci', 'osa'), ('ancio', 'sa'), ('ancios', 'a'), ('anciosa', '')]\n",
      "[('', 'ancciosa'), ('a', 'ncciosa'), ('an', 'cciosa'), ('anc', 'ciosa'), ('ancc', 'iosa'), ('ancci', 'osa'), ('anccio', 'sa'), ('anccios', 'a'), ('ancciosa', '')]\n",
      "[('', 'ansioa'), ('a', 'nsioa'), ('an', 'sioa'), ('ans', 'ioa'), ('ansi', 'oa'), ('ansio', 'a'), ('ansioa', '')]\n",
      "[('', 'empoderamento'), ('e', 'mpoderamento'), ('em', 'poderamento'), ('emp', 'oderamento'), ('empo', 'deramento'), ('empod', 'eramento'), ('empode', 'ramento'), ('empoder', 'amento'), ('empodera', 'mento'), ('empoderam', 'ento'), ('empoderame', 'nto'), ('empoderamen', 'to'), ('empoderament', 'o'), ('empoderamento', '')]\n",
      "[('', 'asterístico'), ('a', 'sterístico'), ('as', 'terístico'), ('ast', 'erístico'), ('aste', 'rístico'), ('aster', 'ístico'), ('asterí', 'stico'), ('asterís', 'tico'), ('asteríst', 'ico'), ('asterísti', 'co'), ('asterístic', 'o'), ('asterístico', '')]\n",
      "[('', 'gratuíto'), ('g', 'ratuíto'), ('gr', 'atuíto'), ('gra', 'tuíto'), ('grat', 'uíto'), ('gratu', 'íto'), ('gratuí', 'to'), ('gratuít', 'o'), ('gratuíto', '')]\n",
      "[('', 'entertido'), ('e', 'ntertido'), ('en', 'tertido'), ('ent', 'ertido'), ('ente', 'rtido'), ('enter', 'tido'), ('entert', 'ido'), ('enterti', 'do'), ('entertid', 'o'), ('entertido', '')]\n",
      "[('', 'ritimo'), ('r', 'itimo'), ('ri', 'timo'), ('rit', 'imo'), ('riti', 'mo'), ('ritim', 'o'), ('ritimo', '')]\n",
      "[('', 'indiota'), ('i', 'ndiota'), ('in', 'diota'), ('ind', 'iota'), ('indi', 'ota'), ('indio', 'ta'), ('indiot', 'a'), ('indiota', '')]\n",
      "[('', 'tomare'), ('t', 'omare'), ('to', 'mare'), ('tom', 'are'), ('toma', 're'), ('tomar', 'e'), ('tomare', '')]\n",
      "[('', 'seje'), ('s', 'eje'), ('se', 'je'), ('sej', 'e'), ('seje', '')]\n",
      "[('', 'provalecer'), ('p', 'rovalecer'), ('pr', 'ovalecer'), ('pro', 'valecer'), ('prov', 'alecer'), ('prova', 'lecer'), ('proval', 'ecer'), ('provale', 'cer'), ('provalec', 'er'), ('provalece', 'r'), ('provalecer', '')]\n",
      "[('', 'esteje'), ('e', 'steje'), ('es', 'teje'), ('est', 'eje'), ('este', 'je'), ('estej', 'e'), ('esteje', '')]\n",
      "[('', 'mindigo'), ('m', 'indigo'), ('mi', 'ndigo'), ('min', 'digo'), ('mind', 'igo'), ('mindi', 'go'), ('mindig', 'o'), ('mindigo', '')]\n",
      "[('', 'célebro'), ('c', 'élebro'), ('cé', 'lebro'), ('cél', 'ebro'), ('céle', 'bro'), ('céleb', 'ro'), ('célebr', 'o'), ('célebro', '')]\n",
      "[('', 'pertubar'), ('p', 'ertubar'), ('pe', 'rtubar'), ('per', 'tubar'), ('pert', 'ubar'), ('pertu', 'bar'), ('pertub', 'ar'), ('pertuba', 'r'), ('pertubar', '')]\n",
      "1.08% de 186 palavras, desconhecida é 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            desconhecida += (correta not in vocabulario)\n",
    "    taxa_acerto = round(acertou * 100 / numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100 / numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecida é {taxa_desconhecida}%\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incrementando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "palavra_exemplo = \"lóigica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4% de 186 palavras, desconhecida é 6.99%\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrigindo os principais erros de digitação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trocando letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alígica', 'blígica', 'clígica', 'dlígica', 'elígica', 'flígica', 'glígica', 'hlígica', 'ilígica', 'jlígica', 'klígica', 'llígica', 'mlígica', 'nlígica', 'olígica', 'plígica', 'qlígica', 'rlígica', 'slígica', 'tlígica', 'ulígica', 'vlígica', 'wlígica', 'xlígica', 'ylígica', 'zlígica', 'àlígica', 'álígica', 'âlígica', 'ãlígica', 'èlígica', 'élígica', 'êlígica', 'ìlígica', 'ílígica', 'îlígica', 'òlígica', 'ólígica', 'ôlígica', 'õlígica', 'ùlígica', 'úlígica', 'ûlígica', 'çlígica', 'laígica', 'lbígica', 'lcígica', 'ldígica', 'leígica', 'lfígica', 'lgígica', 'lhígica', 'liígica', 'ljígica', 'lkígica', 'llígica', 'lmígica', 'lnígica', 'loígica', 'lpígica', 'lqígica', 'lrígica', 'lsígica', 'ltígica', 'luígica', 'lvígica', 'lwígica', 'lxígica', 'lyígica', 'lzígica', 'làígica', 'láígica', 'lâígica', 'lãígica', 'lèígica', 'léígica', 'lêígica', 'lìígica', 'líígica', 'lîígica', 'lòígica', 'lóígica', 'lôígica', 'lõígica', 'lùígica', 'lúígica', 'lûígica', 'lçígica', 'líagica', 'líbgica', 'lícgica', 'lídgica', 'líegica', 'lífgica', 'líggica', 'líhgica', 'líigica', 'líjgica', 'líkgica', 'lílgica', 'límgica', 'língica', 'líogica', 'lípgica', 'líqgica', 'lírgica', 'lísgica', 'lítgica', 'líugica', 'lívgica', 'líwgica', 'líxgica', 'líygica', 'lízgica', 'líàgica', 'líágica', 'líâgica', 'líãgica', 'líègica', 'líégica', 'líêgica', 'líìgica', 'líígica', 'líîgica', 'líògica', 'líógica', 'líôgica', 'líõgica', 'líùgica', 'líúgica', 'líûgica', 'líçgica', 'lígaica', 'lígbica', 'lígcica', 'lígdica', 'lígeica', 'lígfica', 'líggica', 'líghica', 'lígiica', 'lígjica', 'lígkica', 'líglica', 'lígmica', 'lígnica', 'lígoica', 'lígpica', 'lígqica', 'lígrica', 'lígsica', 'lígtica', 'líguica', 'lígvica', 'lígwica', 'lígxica', 'lígyica', 'lígzica', 'lígàica', 'lígáica', 'lígâica', 'lígãica', 'lígèica', 'lígéica', 'lígêica', 'lígìica', 'lígíica', 'lígîica', 'lígòica', 'lígóica', 'lígôica', 'lígõica', 'lígùica', 'lígúica', 'lígûica', 'lígçica', 'lígiaca', 'lígibca', 'lígicca', 'lígidca', 'lígieca', 'lígifca', 'lígigca', 'lígihca', 'lígiica', 'lígijca', 'lígikca', 'lígilca', 'lígimca', 'líginca', 'lígioca', 'lígipca', 'lígiqca', 'lígirca', 'lígisca', 'lígitca', 'lígiuca', 'lígivca', 'lígiwca', 'lígixca', 'lígiyca', 'lígizca', 'lígiàca', 'lígiáca', 'lígiâca', 'lígiãca', 'lígièca', 'lígiéca', 'lígiêca', 'lígiìca', 'lígiíca', 'lígiîca', 'lígiòca', 'lígióca', 'lígiôca', 'lígiõca', 'lígiùca', 'lígiúca', 'lígiûca', 'lígiçca', 'lígicaa', 'lígicba', 'lígicca', 'lígicda', 'lígicea', 'lígicfa', 'lígicga', 'lígicha', 'lígicia', 'lígicja', 'lígicka', 'lígicla', 'lígicma', 'lígicna', 'lígicoa', 'lígicpa', 'lígicqa', 'lígicra', 'lígicsa', 'lígicta', 'lígicua', 'lígicva', 'lígicwa', 'lígicxa', 'lígicya', 'lígicza', 'lígicàa', 'lígicáa', 'lígicâa', 'lígicãa', 'lígicèa', 'lígicéa', 'lígicêa', 'lígicìa', 'lígicía', 'lígicîa', 'lígicòa', 'lígicóa', 'lígicôa', 'lígicõa', 'lígicùa', 'lígicúa', 'lígicûa', 'lígicça', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaà', 'lígicaá', 'lígicaâ', 'lígicaã', 'lígicaè', 'lígicaé', 'lígicaê', 'lígicaì', 'lígicaí', 'lígicaî', 'lígicaò', 'lígicaó', 'lígicaô', 'lígicaõ', 'lígicaù', 'lígicaú', 'lígicaû', 'lígicaç', 'ígica', 'lgica', 'líica', 'lígca', 'lígia', 'lígic', 'lígica', 'aígica', 'bígica', 'cígica', 'dígica', 'eígica', 'fígica', 'gígica', 'hígica', 'iígica', 'jígica', 'kígica', 'lígica', 'mígica', 'nígica', 'oígica', 'pígica', 'qígica', 'rígica', 'sígica', 'tígica', 'uígica', 'vígica', 'wígica', 'xígica', 'yígica', 'zígica', 'àígica', 'áígica', 'âígica', 'ãígica', 'èígica', 'éígica', 'êígica', 'ìígica', 'íígica', 'îígica', 'òígica', 'óígica', 'ôígica', 'õígica', 'ùígica', 'úígica', 'ûígica', 'çígica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'líaica', 'líbica', 'lícica', 'lídica', 'líeica', 'lífica', 'lígica', 'líhica', 'líiica', 'líjica', 'líkica', 'lílica', 'límica', 'línica', 'líoica', 'lípica', 'líqica', 'lírica', 'lísica', 'lítica', 'líuica', 'lívica', 'líwica', 'líxica', 'líyica', 'lízica', 'líàica', 'líáica', 'líâica', 'líãica', 'líèica', 'líéica', 'líêica', 'líìica', 'lííica', 'líîica', 'líòica', 'líóica', 'líôica', 'líõica', 'líùica', 'líúica', 'líûica', 'líçica', 'lígaca', 'lígbca', 'lígcca', 'lígdca', 'lígeca', 'lígfca', 'líggca', 'líghca', 'lígica', 'lígjca', 'lígkca', 'líglca', 'lígmca', 'lígnca', 'lígoca', 'lígpca', 'lígqca', 'lígrca', 'lígsca', 'lígtca', 'líguca', 'lígvca', 'lígwca', 'lígxca', 'lígyca', 'lígzca', 'lígàca', 'lígáca', 'lígâca', 'lígãca', 'lígèca', 'lígéca', 'lígêca', 'lígìca', 'lígíca', 'lígîca', 'lígòca', 'lígóca', 'lígôca', 'lígõca', 'lígùca', 'lígúca', 'lígûca', 'lígçca', 'lígiaa', 'lígiba', 'lígica', 'lígida', 'lígiea', 'lígifa', 'lígiga', 'lígiha', 'lígiia', 'lígija', 'lígika', 'lígila', 'lígima', 'lígina', 'lígioa', 'lígipa', 'lígiqa', 'lígira', 'lígisa', 'lígita', 'lígiua', 'lígiva', 'lígiwa', 'lígixa', 'lígiya', 'lígiza', 'lígiàa', 'lígiáa', 'lígiâa', 'lígiãa', 'lígièa', 'lígiéa', 'lígiêa', 'lígiìa', 'lígiía', 'lígiîa', 'lígiòa', 'lígióa', 'lígiôa', 'lígiõa', 'lígiùa', 'lígiúa', 'lígiûa', 'lígiça', 'lígica', 'lígicb', 'lígicc', 'lígicd', 'lígice', 'lígicf', 'lígicg', 'lígich', 'lígici', 'lígicj', 'lígick', 'lígicl', 'lígicm', 'lígicn', 'lígico', 'lígicp', 'lígicq', 'lígicr', 'lígics', 'lígict', 'lígicu', 'lígicv', 'lígicw', 'lígicx', 'lígicy', 'lígicz', 'lígicà', 'lígicá', 'lígicâ', 'lígicã', 'lígicè', 'lígicé', 'lígicê', 'lígicì', 'lígicí', 'lígicî', 'lígicò', 'lígicó', 'lígicô', 'lígicõ', 'lígicù', 'lígicú', 'lígicû', 'lígicç', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaà', 'lígicaá', 'lígicaâ', 'lígicaã', 'lígicaè', 'lígicaé', 'lígicaê', 'lígicaì', 'lígicaí', 'lígicaî', 'lígicaò', 'lígicaó', 'lígicaô', 'lígicaõ', 'lígicaù', 'lígicaú', 'lígicaû', 'lígicaç']\n"
     ]
    }
   ],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "\n",
    "palavra_exemplo = \"lígica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trocando letras de posição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "\n",
    "palavra_exemplo = \"lógiac\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "#print(palavras_geradas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(\"lgóica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras, desconhecida é 6.99%\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um corretor turbinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# palavras que o corretor é capaz de corrigir\n",
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = \"lóiigica\"\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "\"lógica\" in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691744"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo os melhores candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    print(len(candidatos))\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9726a43947539454533853d3201a59fdf1078c50b678dc55536f50e7896ad32c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
